{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try using https://daler.github.io/pybedtools/autodocs/pybedtools.bedtool.BedTool.window_maker.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from pybedtools import BedTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=[], dest='window_gap', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help='Size of the gap between each rolling window in bp', metavar=None)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='rolling_window')\n",
    "#parser.add_argument('directory_path', type=str, help='Location of base directory')\n",
    "#better to use relative path\n",
    "parser.add_argument('file_names', type=str, help='Name of folder and filenames for the promoters extracted')\n",
    "parser.add_argument('promoter_bedfile', type=str, help='Input location of promoter bedfile')\n",
    "parser.add_argument('motifs_bed', type=str, help='Input location of motifs bed file')\n",
    "parser.add_argument('TFBS_coverage_bed', type=str, help='Output location of rolling window bed file')\n",
    "parser.add_argument('window_bed', type=str, help='Output location of rolling window bed file')\n",
    "parser.add_argument('window_size', type=int, help='Size of the rolling window in bp')\n",
    "parser.add_argument('step_size', type=int, help='Size of the window offset in bp')\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_overlapping_proms(promoter_bed,output_bed):\n",
    "    \"\"\"function to take an input promoter bed file and output a bedfile containing a list of promoters which overlap\"\"\"\n",
    "    #read in promoters\n",
    "    proms_df = pd.read_table(promoter_bed, sep='\\t', header=None)\n",
    "    cols = ['chr','start','stop','AGI','dot1','strand','source','type','dot2','attributes']\n",
    "    proms_df.columns = cols\n",
    "    #create bedtools object of promoters\n",
    "    proms_bed = BedTool(promoter_bed)\n",
    "    #c = columns to apply function to\n",
    "    #o = count number of merged promoters, name the first and last promoter that were merged\n",
    "    merged = proms_bed.merge(c=4, o=['count_distinct','first', 'last'])\n",
    "    #write to bufer\n",
    "    merged_buffer = io.StringIO()\n",
    "    merged_buffer.write(str(merged))\n",
    "    merged_buffer.seek(0)\n",
    "    #read as dataframe\n",
    "    overlapping = pd.read_table(merged_buffer, sep='\\t', header=None)\n",
    "    cols2 = ['chr','start','stop', 'number_of_overlaps', 'first_overlap','second_overlap']\n",
    "    overlapping.columns = cols2\n",
    "    #select only features made of more than one promtoer that were merged as overlapping\n",
    "    overlapping_only = overlapping[overlapping.number_of_overlaps >= 2]\n",
    "    overlapping_only.to_csv(output_bed,index=False,sep='\\t',header=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def window_splitold(promoter_bed, motifs_bed, output_bed, window_size, step_size):\n",
    "#     #separate promoters into dfs by strand\n",
    "#     proms_df = pd.read_table(promoter_bed, sep='\\t', header=None)\n",
    "#     cols1 = ['chr','start','stop','AGI','dot1','strand','source','type','dot2','attributes']\n",
    "#     proms_df.columns = cols1\n",
    "# #     proms_pos = proms_df[proms_df.strand == '+']\n",
    "# #     proms_neg = proms_df[proms_df.strand == '-']\n",
    "#     for i,data in proms_df.iterrows():\n",
    "#         #range function is start, stop, step\n",
    "#         for num in range(proms_df.loc[i, 'start'], proms_df.loc[i, 'start'] - window_size, step_size):\n",
    "#             chunk = proms_df[num:num + window_size]\n",
    "#             #assert len(chunk) == window_size\n",
    "#             yield chunk\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_split(promoter_bed, output_bed, window_size, step_size):\n",
    "    \"\"\"function to split promoters into rolling windows\"\"\"\n",
    "    #separate promoters into dfs by strand\n",
    "    proms_df = pd.read_table(promoter_bed, sep='\\t', header=None)\n",
    "    cols1 = ['chr','start','stop','AGI','dot1','strand','source','type','dot2','attributes']\n",
    "    proms_df.columns = cols1\n",
    "    proms_pos = proms_df[proms_df.strand == '+']\n",
    "    proms_neg = proms_df[proms_df.strand == '-']\n",
    "    #fool bedtools makewindow so that the first window is actually made from the ATG for the positive strand\n",
    "    proms_pos_copy = proms_pos.copy()\n",
    "    proms_pos_copy['length'] = proms_pos.stop-proms_pos.start\n",
    "    proms_pos_copy['altered_start'] = proms_pos.stop\n",
    "    proms_pos_copy['altered_stop'] = proms_pos.start + 2*proms_pos_copy.length\n",
    "    proms_changed = proms_pos_copy[['chr','altered_start','altered_stop','AGI','dot1','strand','source','type','dot2','attributes']]\n",
    "   \n",
    "    #write to temporary bed buffers\n",
    "    pos_buffer = io.StringIO()\n",
    "    neg_buffer = io.StringIO()\n",
    "    proms_changed.to_csv(pos_buffer,index=False,sep='\\t',header=None)\n",
    "    proms_neg.to_csv(neg_buffer,index=False,sep='\\t',header=None)\n",
    "    pos_buffer.seek(0)\n",
    "    neg_buffer.seek(0)\n",
    "    \n",
    "    pos_proms = BedTool(pos_buffer)\n",
    "    neg_proms = BedTool(neg_buffer)\n",
    "    #make the sliding windows\n",
    "    #w = window size\n",
    "    #s = step size\n",
    "    #n = no. of windows - note there seems to be a bug, window size is one below what you put\n",
    "    #i = srcwinnum (use source interval name with the window number)\n",
    "    #reverse = reverse numbering of windows in output - used this for negative strand promoters so window 1 starts at the ATG\n",
    "    #note - the windows in the reverse strand get cut off if I use a step_size bigger than 1, so I will manually remove windows of the incorrect step size\n",
    "    windows_pos = BedTool().window_maker(b=pos_proms, w=window_size,s=50, i='srcwinnum')\n",
    "    windows_neg = BedTool().window_maker(b=neg_proms, w=window_size,s=50, i='srcwinnum')#,reverse=True\n",
    "    #make buffer\n",
    "    window_pos_buffer = io.StringIO()\n",
    "    window_neg_buffer = io.StringIO()\n",
    "    #write bedfile_like buffer\n",
    "    window_pos_buffer.write(str(windows_pos))\n",
    "    window_pos_buffer.seek(0)\n",
    "    window_neg_buffer.write(str(windows_neg))\n",
    "    window_neg_buffer.seek(0)\n",
    "    #create df\n",
    "    window_pos_df = pd.read_table(window_pos_buffer, sep='\\t', header=None)\n",
    "    window_neg_df = pd.read_table(window_neg_buffer, sep='\\t', header=None)\n",
    "    cols = ['chr', 'start','stop','window']\n",
    "    window_pos_df.columns = cols\n",
    "    window_neg_df.columns = cols\n",
    "    window_neg_df = window_neg_df.astype({'chr':'int','start': 'int', 'stop':'int', 'window':'str'})\n",
    "    window_pos_df = window_pos_df.astype({'chr':'int','start': 'int', 'stop':'int', 'window':'str'})\n",
    "    \n",
    "    \n",
    "    #reverse the start/stop changes that fooled bedtools makewindow\n",
    "    pos_df_corrected = window_pos_df.copy()\n",
    "    ### need to merge this df with proms_pos using AGI code. then make distance the original stop - 1 to the chunk stop\n",
    "    #Make AGI column\n",
    "    pos_df_corrected = pos_df_corrected.assign(AGI=pos_df_corrected.window.str.extract(r'(.*?)\\_'))\n",
    "\n",
    "    #Merge with proms_pos using AGI code\n",
    "    merged = pd.merge(pos_df_corrected, proms_pos, on='AGI', how='left',suffixes=('','_wholeprom'))    \n",
    "    \n",
    "    merged['distance'] = merged.stop-merged.stop_wholeprom\n",
    "    #create window length column\n",
    "    merged['window_length'] = merged.stop-merged.start\n",
    "    \n",
    "    merged['correct_start'] = merged.stop - 2*merged.distance\n",
    "    merged['correct_stop'] = merged.correct_start + merged.window_length\n",
    "    #filter by correct_stop if it is outside the range of the promoter\n",
    "\n",
    "    merged = merged[['chr','correct_start','correct_stop','window']]\n",
    "    #rename columns\n",
    "    merged.rename(columns={'correct_start':'start', 'correct_stop':'stop'}, inplace=True)\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    #Merge positive and negative strand windows\n",
    "    merged_all = pd.merge(window_neg_df,merged, how='outer')\n",
    "    #merged_all.to_csv(output_bed,index=False,sep='\\t',header=None)\n",
    "    \n",
    "    #filter lengths so they are only = 100bp\n",
    "    window_lengths = merged_all.copy()\n",
    "    window_lengths =  merged_all.assign(length=((merged_all.stop) - merged_all.start))\n",
    "    removed= window_lengths.loc[window_lengths.length == 100]\n",
    "    \n",
    "    #sort by chr, start\n",
    "    sorted_removed = removed.sort_values(['chr','start']).reset_index(drop=True)\n",
    "    #remove length column\n",
    "    sorted_removed = sorted_removed[['chr','start','stop','window']]\n",
    "    #write to bed file\n",
    "    sorted_removed.to_csv(output_bed,index=False,sep='\\t',header=None)\n",
    "    pos_buffer.close()\n",
    "    neg_buffer.close()\n",
    "    window_pos_buffer.close()\n",
    "    window_neg_buffer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = 'non-overlapping_includingbidirectional_all_genes_newannotation'\n",
    "directory_path = '../..'\n",
    "promoter_bedfile = f'../../data/output/{file_names}/FIMO/promoters_5UTR.bed'\n",
    "#motifs_bed = f'../../data/output/{file_names}/FIMO/promoters_5UTR_motifs.bed'\n",
    "TFBS_coverage_bed = f'{directory_path}/data/output/{file_names}/rolling_window/TFBS_coverage_rw/promoters_5UTR_TFBS_coverage_rw.bed'\n",
    "window_bed = f'{directory_path}/data/output/{file_names}/rolling_window/promoters_5UTR_windows.bed'\n",
    "overlapping_proms = f'{directory_path}/data/output/{file_names}/overlapping_promoters.bed'\n",
    "window_size = 100\n",
    "step_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../../data/output/non-overlapping_includingbidirectional_all_genes_newannotation  already exists\n"
     ]
    }
   ],
   "source": [
    "#make directory for the output files to be exported to\n",
    "#dirName = f'{args.directory_path}/data/output/{args.file_names}'\n",
    "dirName = f'{directory_path}/data/output/{file_names}'\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" created\") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../../data/output/non-overlapping_includingbidirectional_all_genes_newannotation/rolling_window  already exists\n"
     ]
    }
   ],
   "source": [
    "#make directory for the output files to be exported to\n",
    "#dirName = f'{args.directory_path}/data/output/{args.file_names}'\n",
    "dirName = f'{directory_path}/data/output/{file_names}/rolling_window'\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" created\") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../../data/output/non-overlapping_includingbidirectional_all_genes_newannotation/rolling_window/TFBS_coverage_rw  already exists\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_overlapping_proms(promoter_bedfile,overlapping_proms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "proms = window_split(promoter_bedfile, window_bed, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "proms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PromoterArchitecturePipeline] *",
   "language": "python",
   "name": "conda-env-PromoterArchitecturePipeline-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
